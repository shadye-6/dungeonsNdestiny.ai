# main.py
from interface.cli import get_player_input, display_output
from memory.working import WorkingMemory
from memory.persistent import PersistentMemory
from memory.summarizer import summarize_for_memory
from memory.embeddings import embed_text
from llm.story_engine import generate_response
from llm.prompt_builder import build_prompt

# Initialize memories
working_mem = WorkingMemory(limit=5)
persistent_mem = PersistentMemory(path="storage/world_state.json")

print("üõ°Ô∏è  AI Dungeon Master is ready! Type 'exit' to quit.")

# Main loop
while True:
    # 1Ô∏è‚É£ Get player input
    player_input = get_player_input()
    if player_input.lower() in ["exit", "quit"]:
        print("Exiting AI Dungeon Master...")
        break

    # 2Ô∏è‚É£ Retrieve relevant persistent memory
    retrieved_context = "\n".join(persistent_mem.retrieve(player_input, top_k=3))

    # 3Ô∏è‚É£ Get working memory context
    working_context = working_mem.get_context()

    # 4Ô∏è‚É£ Build prompt for LLM
    prompt = build_prompt(working_context, retrieved_context, player_input)

    # 5Ô∏è‚É£ Generate DM response
    response = generate_response(prompt)

    # 6Ô∏è‚É£ Display output to player
    display_output(response)

    # 7Ô∏è‚É£ Update working memory
    working_mem.add_turn("Player", player_input)
    working_mem.add_turn("DM", response)

    # 8Ô∏è‚É£ Summarize DM response for long-term memory
    summary = summarize_for_memory(response)
    summary_emb = embed_text(summary)
    persistent_mem.add_memory(summary, summary_emb)
